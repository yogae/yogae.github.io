---
layout: post
title:  "Amazon EMR"
date: 2019-03-25
categories: SAA
author: yogae
---

Amazon EMR은 비즈니스, 연구원, 데이터 분석가 및 개발자가 막대한 양의 데이터를 간편하게, 비용 효율적으로 처리할 수 있는 웹 서비스입니다. 이 서비스는 호스팅된 하둡 프레임워크를 사용합니다. 하둡 프레임워크는 Amazon Elastic Compute Cloud(Amazon EC2)와 Amazon Simple Storage Service(Amazon S3)의 웹 규모 인프라에서 실행됩니다.

Amazon EMR을 사용해 웹 인덱싱, 데이터 마이닝, 로그 파일 분석, 시스템 학습, 재무 분석, 과학 시뮬레이션, 생물정보학 연구와 같은 애플리케이션의 데이터 집약적인 작업을 수행하는 데 필요한 적당한 용량을 즉시 프로비저닝할 수 있습니다. 

Amazon EMR은 대용량 데이터의 빠르고 효율적인 처리가 필요한 작업에 이상적입니다.

Amazon EMR는 클러스터가 종료되는 방식(자동 또는 수동)을 제어하는 구성 옵션을 제공합니다. 클러스터가 자동으로 종료되도록 구성할 경우 모든 단계가 완료된 후 클러스터가 종료됩니다. 이 클러스터를 일시적 클러스터라고 합니다. 하지만 처리가 완료된 후에도 클러스터가 계속 실행되도록 구성하여 클러스터가 더 이상 필요 없을 때 수동으로 클러스터를 종료하도록 선택할 수 있습니다.

원하는 만큼 얼마든지 클러스터를 시작할 수 있습니다. 모든 클러스터에 대한 인스턴스 수는 20개로 제한됩니다.

Amazon EMR은 Amazon SimpleDB의 계정에 하둡 작업, 태스크, 태스크 시도에 대한 상태 정보를 저장합니다. 

- **클러스터가 종료된 후에도 EBS 볼륨에 데이터를 유지할 수 있습니까?**

현재는 클러스터가 종료되면 Amazon EMR에서 볼륨을 삭제합니다. 클러스터의 수명 주기와 관계없이 데이터를 유지하려는 경우, Amazon S3를 데이터 스토어로 사용하는 것이 좋습니다.

## 개요

### 클러스터

Amazon EMR의 중심 구성 요소는 *클러스터*입니다. 클러스터는 Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스의 컬렉션입니다.

### 노드

클러스터에 있는 각 인스턴스를 *노드*라고 합니다. 각 노드에는 *노드 유형*이라고 하는 클러스터 내의 역할이 있습니다. 또한 Amazon EMR는 각 노드 유형에 다양한 소프트웨어 구성 요소를 설치하여 각 노드에 Apache Hadoop과 같은 분산 애플리케이션의 역할을 부여합니다.

### 노드 유형

- **마스터 노드**: 처리를 위해 다른 노드 간에 데이터와 작업의 배포를 조정하는 소프트웨어 구성 요소를 실행하여 클러스터를 관리하는 노드입니다. 마스터 노드는 작업 상태를 추적하고 클러스터 상태를 모니터링합니다. 모든 클러스터에는 마스터 노드가 있으며 마스터 노드만으로 단일 노드 클러스터를 생성할 수 있습니다.
- **코어 노드**: 클러스터의 Hadoop 분산 파일 시스템(HDFS)에서 작업을 실행하고 데이터를 저장하는 소프트웨어 구성 요소가 있는 노드입니다. 다중 노드 클러스터에는 1개 이상의 코어 노드가 있습니다.
- **작업 노드**: 작업만 실행하고 HDFS에 데이터를 저장하지는 않는 소프트웨어 구성 요소가 있는 노드입니다. 작업 노드는 선택 사항입니다.

### Amazon EMR 아키텍처 개요

#### 스토리지

- 하둡 분산 파일 시스템(HDFS)

  하둡 분산 파일 시스템(HDFS)은 확장 가능한 하둡용 분산 파일 시스템입니다. HDFS는 클러스터가 종료될 때 회수되는 휘발성 스토리지입니다. HDFS는 MapReduce 처리 중 중간 결과를 캐시에 저장하려는 경우나 상당한 임의 I/O가 있는 워크로드에 유용합니다.

- EMR 파일 시스템(EMRFS)

  EMR 파일 시스템(EMRFS) 사용을 통해 Amazon EMR는 HDFS 파일 시스템과 같은 방식으로 Amazon S3에 저장된 데이터에 직접 액세스할 수 있는 기능을 추가하도록 Hadoop을 확장합니다. HDFS 또는 Amazon S3을 클러스터의 파일 시스템으로 사용할 수 있습니다. 대부분은 Amazon S3을 사용하여 입력 및 출력 데이터를 저장하고 중간 결과는 HDFS에 저장됩니다.

- 로컬 파일 시스템

  로컬 파일 시스템은 로컬로 연결된 디스크를 참조합니다. Hadoop 클러스터를 생성할 때 인스턴스 스토어라는 미리 연결된 디스크 스토리지의 사전 구성된 블록과 함께 제공되는 Amazon EC2 인스턴스에서 각 노드가 생성됩니다. 인스턴스 스토어 볼륨의 데이터는 Amazon EC2 인스턴스의 수명 주기 동안에만 유지됩니다.

#### 클러스터 리소스 관리

리소스 관리 계층은 클러스터 리소스 관리와 데이터 처리 작업의 일정 계획을 담당합니다.

기본적으로 Amazon EMR는 Apache Hadoop 2.0에 도입된 구성 요소인 YARN(Yet Another Resource Negotiator)을 사용하여 여러 데이터 처리 프레임워크에 대한 클러스터 리소스를 중앙에서 관리합니다.

작업 노드를 실행하는 데 종종 스팟 인스턴스가 사용되기 때문에, Amazon EMR은 YARN 작업을 위한 예약 기능을 제공하며 이를 통해 스팟 인스턴스에서 실행 중인 작업 노드가 종료될 경우 실행 중이던 작업이 실패하지 않습니다. Amazon EMR은 애플리케이션 마스터 프로세스가 코어 노드에서만 실행되게 함으로써 이를 지원합니다. 애플리케이션 마스터 프로세스는 실행 중인 작업을 제어하며, 작업 수명 동안 유지되어야 합니다.

#### 데이터 처리 프레임워크

데이터 처리 프레임워크 계층은 데이터를 처리하고 분석하는 데 사용되는 엔진입니다.  YARN에서 실행되거나 고유의 리소스 관리 기능을 갖춘 여러 프레임워크를 사용할 수 있습니다. Amazon EMR에 사용 가능한 기본 처리 프레임워크는 Hadoop MapReduce와 Spark입니다.

- Hadoop MapReduce

  하둡 MapReduce는 분산 컴퓨팅을 위한 오픈 소스 프로그래밍 모델입니다. 이 모델은 사용자가 Map 및 Reduce 함수를 제공하는 동안 모든 로직을 처리하여 병렬 분산 애플리케이션 쓰기 프로세스를 간소화합니다.

  > - MapReduce로 구현한 것인데 매우 어렵고 복잡합니다.
  >
  > - 쿼리를 최적화하기가 어렵고 속도가 더 느려지는 경우가 많다는 어려움이 있습니다.

- Apache Spark

  Spark는 빅 데이터 워크로드를 처리하기 위한 클러스터 프레임워크 및 프로그래밍 모델입니다. 하둡 MapReduce와 마찬가지로, Spark는 오픈 소스 분산 처리 시스템이지만 비순환 방향 그래프를 실행 계획에 사용하며 인 메모리 캐시를 데이터 세트에 활용합니다. Amazon EMR에서 Spark를 실행하면 EMRFS를 사용하여 Amazon S3의 데이터에 직접 액세스할 수 있습니다. Spark는 SparkSQL과 같은 여러 대화형 쿼리 모델을 지원합니다.

  > - 메모리를 활용한 아주 빠른 데이터 처리가 특징입니다.
  > -  Scala를 사용하여 코드가 매우 간단하며, interactive shell을 사용

#### 애플리케이션 및 프로그램

Amazon EMR는 Hive, Pig 및 Spark Streaming 라이브러리와 같은 수많은 애플리케이션을 지원하여 더 높은 수준의 언어를 사용한 처리 워크로드 생성, 기계 학습 알고리즘 활용, 스트리밍 처리 애플리케이션 작성, 데이터 웨어하우스 구축 등의 기능을 제공합니다. 또한 Amazon EMR는 YARN을 사용하는 대신 고유의 클러스터 관리 기능을 갖춘 오픈 소스 프로젝트도 지원합니다.

### EMR Notebooks

EMR Notebooks는 Jupyter Notebook에 기반한 관리 환경으로, 데이터 과학자, 분석가 및 개발자가 EMR 클러스터를 사용하여 데이터를 준비하고 시각화하며, 동료와 협업하고, 애플리케이션을 구축하며, 인터랙티브 분석을 수행할 수 있습니다.

### Amazon EMR 부트스트랩 작업

부트스트랩 작업은 클러스터를 실행하기 전에 사용자에게 사용자 정의 설치 프로그램을 실행하는 방법을 제공하는 Amazon EMR의 기능입니다. 부트스트랩 작업은 클러스터를 실행하기 전에 소프트웨어를 설치하거나 인스턴스를 구성하는 데 사용할 수 있습니다.

### Apache Hive

Hive는 하둡에서 실행되는 오픈 소스 데이터 웨어하우스 및 분석 패키지입니다. Hive는 Hive QL이라는 SQL 기반 언어로 작동합니다. Amazon EMR에서 Hive를 사용하면 Amazon EMR에서 사용할 수 있는 친숙한 유사 SQL 언어와 사용하기 쉬운 도구로 정교한 데이터 처리 애플리케이션을 구현할 수 있습니다. 

기존의 RDMS 시스템은 트랜잭션 의미 체계와 참조 무결성이 필요하며 소소한 업데이트가 수시로 수행되는 경우에 가장 적합합니다. Hive는 대규모 데이터 세트의 오프라인 보고, 변환, 분석에 가장 적합합니다.

Hive는 분할된 테이블을 지원하므로, Amazon EMR 클러스터는 전체 테이블을 검색하는 것이 아니라 실행 중인 쿼리와 관련된 테이블 일부만 검색할 수 있습니다. PIG와 Hive는 둘 다 쿼리 계획 최적화 기능을 제공합니다. PIG는 전체 스크립트에서 쿼리를 최적화할 수 있지만 Hive는 문 수준에서 쿼리를 최적화합니다.

### Impala 사용

Impala는 SQL 구문을 사용하는 대화형 임시 쿼리를 위한 하둡 에코시스템의 오픈 소스 도구입니다. Amazon EMR에서 Hive를 사용할 때와 마찬가지로 Amazon EMR에서 Impala를 사용하면 SQL 구문을 통해 정교한 데이터 처리 애플리케이션을 구현할 수 있습니다.

- 장기 실행 중인 클러스터에서 Hive 대신 Impala를 사용해 임시 쿼리를 수행하십시오. 
- 일시적인 Amazon EMR 클러스터에서 배치 ETL 작업에는 Hive 대신 Impala를 사용하십시오. 
- Impala를 타사 비즈니스 인텔리전스 도구와 함께 사용하십시오. 클라이언트 ODBC 또는 JDBC 드라이버를 클러스터와 연결하여 강력한 시각화 도구 및 대시보드용 엔진으로 Impala를 사용하십시오.

**Impala와 Hive의 차이점은 무엇입니까?**

Impala는 MPP(대량 병렬 처리) 엔진을 사용해 SQL 쿼리를 실행하며, Hive는 MapReduce를 사용해 SQL을 실행합니다. 하지만 Impala는 상당한 양의 메모리 리소스를 사용하며, 클러스터의 가용 메모리 공간은 쿼리가 사용할 수 있는 메모리의 양을 제약합니다.  Impala는 빠른 성능을 낼 수 있도록 구축되었기 때문에 임시 조사에 매우 적합하지만 비싼 쿼리를 실행하거나 아주 큰 데이터 세트를 처리하는 데 상당히 많은 양의 메모리가 필요합니다. 이러한 제약 조건 때문에 속도보다 완료가 더욱 중요한 워크로드의 경우 Hive를 사용하는 것이 좋습니다.

### Pig 사용

Pig는 하둡에서 실행되는 오픈 소스 분석 패키지입니다. Amazon EMR에서 Pig를 사용하면 Amazon EMR에서 사용할 수 있는 친숙한 유사 SQL 언어와 사용하기 쉬운 도구로 정교한 데이터 처리 애플리케이션을 구현할 수 있습니다. Amazon EMR을 사용하면 Pig 애플리케이션을 안정적인 데이터 웨어하우스로 바꾸어 데이터 분석, 모니터링, 비즈니스 인텔리전스 등의 작업을 수행할 수 있습니다.

### HBase 사용

HBase는 Google의 BigTable을 본떠서 만든 비관계형 분산 오픈 소스 데이터베이스입니다. HBase는 데이터가 디스크가 아닌 메모리 안에 저장되므로 데이터를 빠르게 조회할 수 있습니다. HBase는 순차 쓰기 작업에 최적화되어 있으며 배치 처리 삽입, 업데이트 및 삭제에 매우 유용합니다.

### Kinesis 커넥터

커넥터는 EMR에서 Kinesis 스트림의 데이터를 직접 읽고 쿼리할 수 있도록 지원합니다.

